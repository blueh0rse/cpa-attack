{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "workdir = \"data/dataset1\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Load cleartext from the file\n",
    "with open(f'{workdir}/cleartext.txt', 'r') as file:\n",
    "    cleartexts = [list(map(int, line.split())) for line in file.readlines()]\n",
    "\n",
    "# Load power traces; you have 16 trace files\n",
    "traces = [np.loadtxt(f'{workdir}/trace{i}.txt') for i in range(16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleartexts: [39, 168, 54, 116, 93, 36, 132, 228, 1, 64, 93, 235, 21, 241, 187, 168]\n",
      "traces: [21337.6 19891.2 20467.2 ... 20812.8 20876.8 19379.2]\n"
     ]
    }
   ],
   "source": [
    "print(f\"cleartexts: {cleartexts[0]}\")\n",
    "print(f\"traces: {traces[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Hypothesis Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example function to calculate hamming weight\n",
    "def hamming_weight(n):\n",
    "    return bin(n).count('1')\n",
    "\n",
    "# Hypothetical power consumption for one key byte guess across all cleartexts\n",
    "def hypothetical_power(cleartexts, key_guess):\n",
    "    return [hamming_weight(ct ^ key_guess) for ct in cleartexts]\n",
    "\n",
    "# Assume you are guessing the first key byte\n",
    "key_guesses = [hypothetical_power([ct[0] for ct in cleartexts], k) for k in range(256)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key_guesses: [4, 2, 3, 4, 6, 3, 5, 7, 3, 5, 2, 6, 2, 3, 3, 3, 5, 6, 7, 5, 3, 3, 5, 5, 6, 5, 3, 4, 5, 4, 4, 4, 2, 6, 3, 4, 3, 5, 6, 5, 4, 1, 4, 5, 2, 2, 3, 4, 5, 3, 2, 3, 4, 2, 7, 3, 1, 6, 4, 3, 4, 5, 4, 3, 4, 3, 3, 4, 5, 4, 3, 4, 1, 4, 4, 7, 4, 2, 2, 3, 2, 6, 4, 2, 5, 6, 3, 3, 5, 4, 2, 0, 5, 2, 3, 3, 4, 3, 4, 3, 5, 3, 6, 2, 2, 3, 5, 4, 6, 2, 5, 3, 3, 3, 4, 5, 2, 4, 5, 5, 2, 2, 3, 1, 2, 6, 7, 6, 5, 5, 3, 5, 3, 2, 3, 6, 3, 4, 6, 5, 3, 3, 4, 4, 4, 3, 4, 8, 2, 5]\n"
     ]
    }
   ],
   "source": [
    "print(f\"key_guesses: {key_guesses[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Best key guesses: [  4 167  33 150 100 102 116  82 100 109 108 104 165 115  73  51]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pearson_correlation(x, y):\n",
    "    if len(x) != len(y):\n",
    "        print(\"Mismatch:\", len(x), len(y))\n",
    "        raise ValueError(\"Length of x and y must be equal.\")\n",
    "    return np.corrcoef(x, y)[0, 1]\n",
    "\n",
    "def expand_hyp_power(hyp_power, num_points):\n",
    "    length = len(hyp_power)\n",
    "    repeats = num_points // length  # Integer division\n",
    "    remainder = num_points % length  # Remainder of the division\n",
    "    \n",
    "    expanded_array = np.repeat(hyp_power, repeats)\n",
    "    if remainder > 0:\n",
    "        expanded_array = np.concatenate((expanded_array, hyp_power[:remainder]))\n",
    "    \n",
    "    return expanded_array\n",
    "\n",
    "# Assuming traces is a list of arrays, each of size (150, 50000)\n",
    "# Initialize the correlations array with dimensions [16, 256]\n",
    "correlations = np.zeros((16, 256))  # 16 byte indexes and 256 key guesses\n",
    "\n",
    "for byte_index in range(16):  # Assuming 16 key bytes\n",
    "    print(byte_index)\n",
    "    for k in range(256):  # 256 possible key guesses\n",
    "        hyp_power = hypothetical_power([ct[byte_index] for ct in cleartexts], k)\n",
    "        expanded_hyp_power = expand_hyp_power(hyp_power, 50000)\n",
    "        \n",
    "        single_correlations = []\n",
    "        for trace_index in range(150):\n",
    "            actual_trace = traces[byte_index][trace_index, :]\n",
    "            corr = pearson_correlation(expanded_hyp_power, actual_trace)\n",
    "            single_correlations.append(corr)\n",
    "        \n",
    "        mean_corr = np.mean(single_correlations)\n",
    "        correlations[byte_index][k] = mean_corr  # Store the mean correlation for this byte and key guess\n",
    "\n",
    "best_key_guesses = np.argmax(correlations, axis=1)\n",
    "print(\"Best key guesses:\", best_key_guesses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best key guesses: [  4 167  33 150 100 102 116  82 100 109 108 104 165 115  73  51]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best key guesses:\", best_key_guesses)\n",
    "# [  4 167  33 150 100 102 116  82 100 109 108 104 165 115  73  51]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
